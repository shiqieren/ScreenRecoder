package com.hht.oemscreenrecoder.screenrecorder

import android.content.ComponentName
import android.content.Context
import android.content.Intent
import android.content.pm.PackageManager
import android.graphics.Point
import android.hardware.display.DisplayManager
import android.hardware.display.VirtualDisplay
import android.media.MediaCodecInfo
import android.media.MediaCodecInfo.CodecCapabilities
import android.media.MediaCodecInfo.CodecProfileLevel
import android.media.projection.MediaProjection
import android.media.projection.MediaProjectionManager
import android.os.Build
import android.util.Log
import android.view.*
import android.widget.TextView
import android.widget.Toast
import androidx.annotation.RequiresApi
import androidx.core.content.FileProvider
import com.blankj.utilcode.util.PathUtils
import com.hht.oemscreenrecoder.MainActivity
import com.hht.oemscreenrecoder.R
import com.hht.oemscreenrecoder.Settings
import com.hht.oemscreenrecoder.widgets.SaveActivity
import com.hht.oemscreenrecoder.yorm.AudioEncodeConfig
import com.hht.oemscreenrecoder.yorm.AudioSilentFillConfig
import com.hht.oemscreenrecoder.yorm.ScreenRecorder
import com.hht.oemscreenrecoder.yorm.ScreenRecorder.AUDIO_AAC
import com.hht.oemscreenrecoder.yorm.ScreenRecorder.VIDEO_AVC
import com.hht.oemscreenrecoder.yorm.Utils
import com.hht.oemscreenrecoder.yorm.VideoEncodeConfig
import java.io.File
import java.text.SimpleDateFormat
import java.util.*

class ScreenRecordHelper constructor(
    private var context: Context,
    private val listener: OnVideoRecordListener?,
    private var mediaProjection: MediaProjection?
) {
    private val settings: Settings by lazy { Settings.getInstance(context) }
    private var mediaProjectionManager: MediaProjectionManager? = null
    //    private var mediaProjection: MediaProjection? = null
    private var virtualDisplay: VirtualDisplay? = null
    private var source: ScreenRecordingAudioSource? = null
    private var mRecorder: ScreenRecorder? = null
    private var file: File? = null
    private var isAgan: Boolean? = false
    // ç”¨æˆ·åˆ‡æ¢æ ‡è®°ï¼šç”¨æˆ·åˆ‡æ¢æ—¶è·³è¿‡ä¿å­˜å¼¹çª—ï¼Œç›´æ¥ä¿ç•™é»˜è®¤è·¯å¾„çš„æ–‡ä»¶
    private var isUserSwitching: Boolean = false
    // å½•åˆ¶åœæ­¢åŸå› ï¼š0-æ­£å¸¸åœæ­¢ï¼Œ1-æ—¶é•¿é™åˆ¶ï¼Œ2-ç©ºé—´ä¸è¶³
    private var stopReason: Int = Settings.STOP_REASON_NORMAL
    init {
        Log.d(TAG, "init: ScreenRecordHelper")
//        mediaProjectionManager =
//            context.getSystemService(Context.MEDIA_PROJECTION_SERVICE) as? MediaProjectionManager
//        mediaProjection = mediaProjectionManager?.getMediaProjection(RESULT_OK, data!!)
    }

    fun startRecord(source: ScreenRecordingAudioSource) {
        this.source = source
        try {
//            if (mediaProjectionManager == null) {
//                Log.d(TAG, "mediaProjectionManager == nullï¼Œå½“å‰è£…ç½®ä¸æ”¯æŒå½•å±")
//                showToast(R.string.device_not_support_screen_record)
//                return
//            }
            Log.d(TAG, "startRecord: ScreenRecordingAudioSource-->$source")
            startCapturing(mediaProjection!!, source)
            // ç§»é™¤ç«‹å³è°ƒç”¨ onStartRecordï¼Œæ”¹ä¸ºåœ¨å½•åˆ¶çœŸæ­£å¼€å§‹åè°ƒç”¨
            // listener?.onStartRecord() ç°åœ¨åœ¨ ScreenRecorder çš„å›è°ƒä¸­è°ƒç”¨
        } catch (e: Exception) {
            Log.e(TAG, "startRecord:error", e)
            // å½•åˆ¶å¯åŠ¨å¤±è´¥ï¼Œé€šçŸ¥ä¸Šå±‚
            listener?.onCancelRecord()
        }
    }

    private fun showToast(resId: Int) {
        val inflater: LayoutInflater = LayoutInflater.from(context)
        val layout: View = inflater.inflate(R.layout.optoma_toast, null as ViewGroup?)
        val textView: TextView = layout.findViewById(R.id.toast_text)
        textView.setText(resId)
        with(Toast.makeText(context, context.getString(resId), Toast.LENGTH_SHORT)) {
            setGravity(Gravity.BOTTOM or Gravity.END, 0, 0)
            view = layout
            setMargin(0f, 0f)
            show()
        }
    }

    /**
     * é€€å‡ºåº”ç”¨é‡Šæ”¾èµ„æº
     */
    fun clearAll() {
        virtualDisplay?.release()
        virtualDisplay = null
        mediaProjection?.stop()
        mediaProjection = null
    }

    @RequiresApi(Build.VERSION_CODES.N)
    fun resume() {
        mRecorder?.resume()
        listener?.onStartRecord()
    }

    @RequiresApi(Build.VERSION_CODES.N)
    fun pause() {
        mRecorder?.pause()
        listener?.onPauseRecord()
    }

    private fun getVideoSizeWidth(): Int {
        if (settings.getResolutionData() == Settings.RESOLUTION_1920_1080) {
            return VIDEO_SIZE_MAX_WIDTH_1920
        } else if (settings.getResolutionData() == Settings.RESOLUTION_1280_720) {
            return VIDEO_SIZE_MAX_WIDTH_1280
        } else if (settings.getResolutionData() == Settings.RESOLUTION_3840_2160) {
            return VIDEO_SIZE_MAX_WIDTH_3840
        }
        return VIDEO_SIZE_MAX_WIDTH_1280
    }

    private fun getVideoSizeHeight(): Int {
        if (settings.getResolutionData() == Settings.RESOLUTION_1920_1080) {
            return VIDEO_SIZE_MAX_HEIGHT_1080
        } else if (settings.getResolutionData() == Settings.RESOLUTION_1280_720) {
            return VIDEO_SIZE_MAX_HEIGHT_720
        } else if (settings.getResolutionData() == Settings.RESOLUTION_3840_2160) {
            return VIDEO_SIZE_MAX_HEIGHT_2160
        }
        return VIDEO_SIZE_MAX_HEIGHT_720
    }

    private fun newRecorder(
        mediaProjection: MediaProjection, video: VideoEncodeConfig,
        audio: AudioEncodeConfig?, output: File
    ): ScreenRecorder {
        val display = getOrCreateVirtualDisplay(mediaProjection, video)
        val r = ScreenRecorder(video, audio, display, output.absolutePath)
        r.setMediaProject(mediaProjection)

        // ===== è®¾ç½®éŸ³é¢‘é™éŸ³å¡«å……é…ç½® =====
        if (audio != null) {
            val silentFillConfig = loadAudioSilentFillConfig()
            r.setAudioSilentFillConfig(silentFillConfig)
            Log.i(TAG, "â˜…â˜…â˜… AUDIO SILENT FILL CONFIG SET â˜…â˜…â˜… $silentFillConfig")
        }

        r.setCallback(object : ScreenRecorder.Callback {
            override fun onStop(message: Any?) {
                if (message != null && message is Throwable) {
                    message.printStackTrace()
                    output.mkdir()
                    // å½•åˆ¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œé€šçŸ¥ä¸Šå±‚
                    listener?.onCancelRecord()
                } else if (message != null && message is String) {
                    if (isUserSwitching) {
                        // ç”¨æˆ·åˆ‡æ¢åœºæ™¯ï¼šè·³è¿‡ä¿å­˜å¼¹çª—ï¼Œæ–‡ä»¶å·²ä¿å­˜åœ¨é»˜è®¤è·¯å¾„
                        Log.d(TAG, "onStop: ç”¨æˆ·åˆ‡æ¢ä¸­ï¼Œè·³è¿‡ä¿å­˜å¼¹çª—ï¼Œæ–‡ä»¶å·²ä¿å­˜: ${output.absolutePath}")
                        listener?.onEndRecord()
                        // é‡ç½®æ ‡è®°
                        isUserSwitching = false
                        stopReason = Settings.STOP_REASON_NORMAL
                    } else if (isAgan == false) {
                        // æ­£å¸¸åœæ­¢å½•åˆ¶ï¼šæ˜¾ç¤ºä¿å­˜é€‰æ‹©ç•Œé¢
                        val intent = Intent(context, SaveActivity::class.java)
                        intent.flags = Intent.FLAG_ACTIVITY_NEW_TASK
                        intent.putExtra("filePath", output.absolutePath)
                        // ä¼ é€’åœæ­¢åŸå› ç»™ SaveActivity
                        intent.putExtra("stopReason", stopReason)
                        Log.d(TAG, "onStop: å¯åŠ¨SaveActivityï¼ŒstopReason=$stopReason")
                        context.startActivity(intent)
                        listener?.onEndRecord()
                        // é‡ç½®åœæ­¢åŸå› 
                        stopReason = Settings.STOP_REASON_NORMAL
                    } else {
                        // é‡æ–°å½•åˆ¶åœºæ™¯
                        listener?.onEndRecord()
                        stopReason = Settings.STOP_REASON_NORMAL
                    }
                }
            }

            override fun onStart() {
                // å½•åˆ¶çœŸæ­£å¼€å§‹åæ‰è°ƒç”¨ onStartRecord
                Log.d(TAG, "ScreenRecorder onStart - å½•åˆ¶çœŸæ­£å¼€å§‹")
                listener?.onStartRecord()
            }

            override fun onRecording(presentationTimeUs: Long) {}

            override fun onInternalAudioNotAvailable(audioType: Int) {
                Log.w(TAG, "â˜…â˜…â˜… ScreenRecorderHelper: Internal audio not available (audioType=$audioType), notifying listener â˜…â˜…â˜…")
                // é€šçŸ¥ä¸Šå±‚ï¼ˆScreenRecordServiceï¼‰æ˜¾ç¤ºToast
                listener?.onInternalAudioNotAvailable(audioType)
            }
        })
        return r
    }

    /**
     * å½•å±æ–‡ä»¶æ‹·è´åˆ°Uç›˜
     */
//    fun copyVideoToUsb(position:Int) {
//        Log.d(TAG, "copyVideoToUsbsaveFile--------: $newFile")
//        usbFile = File(UsbFlashUtil.getUsbPath().get(position -1), "Screen Record/ScreenRecord_${fileName}.mp4")
//
//        if (newFile!!.exists()) {
//            val outF: FileChannel
//            try {
//                outF = FileOutputStream(usbFile).channel
//                FileInputStream(newFile).channel.transferTo(0, newFile!!.length(), outF)
//            } catch (e: FileNotFoundException) {
//                e.printStackTrace()
//            } catch (e: IOException) {
//                e.printStackTrace()
//            }
//        }
//        deleteFile()
//        newFile?.delete()
//    }


    private fun startCapturing(
        mediaProjection: MediaProjection,
        source: ScreenRecordingAudioSource
    ) {
        val video = createVideoConfig()
        val audio = createAudioConfig(source) // audio can be null
        val format = SimpleDateFormat("yyyyMMdd-HHmmss", Locale.US)
        val fileDirectory = File(PathUtils.getExternalStoragePath() + "/Screen Record")
        if (!fileDirectory.exists()) {
            fileDirectory.mkdir()
        }
        file = File(
            fileDirectory.absolutePath,
            "ScreenRecord_" + format.format(Date())
                    + "_" + video.width + "x" + video.height + ".mp4"
        )

        Log.i(TAG, "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        Log.i(TAG, "â•‘ ğŸ¬ STARTING SCREEN RECORDING")
        Log.i(TAG, "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        Log.i(TAG, "â•‘ Output file:      ${file!!.absolutePath}")
        Log.i(TAG, "â•‘ Video config:     ${video.width}x${video.height} @ ${video.framerate}fps, ${video.bitrate/1000}kbps")
        Log.i(TAG, "â•‘ Audio source:     $source")
        if (audio != null) {
            Log.i(TAG, "â•‘ Audio config:     $audio")
        } else {
            Log.w(TAG, "â•‘ Audio config:     DISABLED (video-only recording)")
        }
        Log.i(TAG, "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

//        fileName = getFormatTime(System.currentTimeMillis()) +"_"+ settings.getResolutionData()
        mRecorder = newRecorder(mediaProjection, video, audio, file!!)
        mRecorder!!.start()
    }

    private fun getFormatTime(time: Long): String? {
        val format = SimpleDateFormat("yyyyMMddHHMMSS", Locale.getDefault())
        val d1 = Date(time)
        return format.format(d1)
    }


    fun deleteFile() {
        file?.delete()
    }
//åªèƒ½è°ƒç”¨ä¸€æ¬¡ï¼Œå¤šæ¬¡ä¼šå¼‚å¸¸
//æ‚¨çš„åº”ç”¨å¿…é¡»åœ¨æ¯ä¸ªåª’ä½“æŠ•å½±ä¼šè¯ä¹‹å‰è¯·æ±‚ç”¨æˆ·åŒæ„ã€‚ç­” æ˜¯å¯¹ createVirtualDisplay() çš„å•æ¬¡è°ƒç”¨ã€‚ä¸€ä¸ª MediaProjection ä»¤ç‰Œ åªèƒ½ä½¿ç”¨ä¸€æ¬¡è¿›è¡Œè°ƒç”¨ã€‚
//åœ¨ Android 14 æˆ–æ›´é«˜ç‰ˆæœ¬ä¸­ï¼ŒcreateVirtualDisplay() æ–¹æ³•ä¼šæŠ›å‡º SecurityExceptionï¼ˆå¦‚æœæ‚¨çš„ åº”ç”¨ä¼šæ‰§è¡Œä»¥ä¸‹ä»»ä¸€æ“ä½œï¼š
//å°†ä» createScreenCaptureIntent() è¿”å›çš„ Intent å®ä¾‹å¤šæ¬¡ä¼ é€’åˆ° getMediaProjection()
//å¯¹åŒä¸€ä¸ª MediaProjection å¤šæ¬¡è°ƒç”¨ createVirtualDisplay() å®ä¾‹

    private fun getOrCreateVirtualDisplay(
        mediaProjection: MediaProjection,
        config: VideoEncodeConfig
    ): VirtualDisplay {
        if (virtualDisplay == null) {
            virtualDisplay = mediaProjection.createVirtualDisplay(
                "ScreenRecorder-display",
                config.width, config.height, 1 /*dpi*/,
                DisplayManager.VIRTUAL_DISPLAY_FLAG_AUTO_MIRROR,
                null /*surface*/, null, null
            )
        } else {
            // resize if size not matched
            val size = Point()
            virtualDisplay!!.display.getSize(size)
            if (size.x != config.width || size.y != config.height) {
                virtualDisplay!!.resize(config.width, config.height, 1)
            }
        }
        return virtualDisplay!!
    }

    fun isAgan() {
        isAgan = true
    }

    fun startAgan() {
        isAgan = false
    }

    /**
     * è®¾ç½®ç”¨æˆ·åˆ‡æ¢æ ‡è®°
     * ç”¨æˆ·åˆ‡æ¢æ—¶è°ƒç”¨æ­¤æ–¹æ³•ï¼Œåœæ­¢å½•åˆ¶æ—¶å°†è·³è¿‡ä¿å­˜å¼¹çª—ï¼Œç›´æ¥ä¿ç•™é»˜è®¤è·¯å¾„çš„æ–‡ä»¶
     */
    fun setUserSwitching(switching: Boolean) {
        isUserSwitching = switching
        Log.d(TAG, "setUserSwitching: $switching")
    }

    /**
     * è®¾ç½®å½•åˆ¶åœæ­¢åŸå› 
     * @param reason åœæ­¢åŸå› ï¼šSettings.STOP_REASON_NORMAL/TIME_LIMIT/LOW_SPACE
     */
    fun setStopReason(reason: Int) {
        stopReason = reason
        Log.d(TAG, "setStopReason: $reason")
    }

    fun stopRecorder() {
        try {
            if (mRecorder != null) {
                mRecorder!!.quit()
            }
            mRecorder = null
        } catch (e: java.lang.Exception) {
            Log.e(TAG, "stopRecorder: error-->${e.printStackTrace()}")
        }finally {
            listener?.onEndRecord()
        }
    }

    private fun createAudioConfig(source: ScreenRecordingAudioSource): AudioEncodeConfig? {
        try {
            when (source) {
                ScreenRecordingAudioSource.NONE -> return null
                else -> {
                    // å¢å¼ºéŸ³é¢‘ç¼–ç å™¨é…ç½®çš„é”™è¯¯å¤„ç†
                    if (Utils.mAacCodecInfos.isEmpty()) {
                        Log.w(TAG, "No AAC codec available, falling back to video-only recording")
                        return null
                    }

                    // ===== æ™ºèƒ½ç¼–è§£ç å™¨é€‰æ‹© - ä¿®å¤ç¡¬ç¼–ç ç´¢å¼•[1]çš„è‡´å‘½é—®é¢˜ =====
                    var selectedCodec: MediaCodecInfo? = null
                    var selectedCapabilities: CodecCapabilities? = null
                    var selectedProfile = MediaCodecInfo.CodecProfileLevel.AACObjectLC // é»˜è®¤ä½¿ç”¨æœ€å…¼å®¹çš„AAC-LC
                    var selectedSampleRate = 44100 // é»˜è®¤é‡‡æ ·ç‡
                    var selectedChannelCount = 1 // é»˜è®¤å•å£°é“

                    // éå†æ‰€æœ‰å¯ç”¨çš„AACç¼–è§£ç å™¨ï¼Œå¯»æ‰¾æœ€å…¼å®¹çš„
                    for (codecInfo in Utils.mAacCodecInfos) {
                        try {
                            val caps = codecInfo.getCapabilitiesForType(AUDIO_AAC)
                            val audioCaps = caps.audioCapabilities

                            if (audioCaps == null) {
                                Log.d(TAG, "Codec ${codecInfo.name} has no audio capabilities, skipping")
                                continue
                            }

                            // éªŒè¯é‡‡æ ·ç‡æ”¯æŒ
                            val supportedSampleRates = audioCaps.supportedSampleRates
                            var sampleRateSupported = false
                            var fallbackSampleRate = -1

                            if (supportedSampleRates != null && supportedSampleRates.isNotEmpty()) {
                                for (rate in supportedSampleRates) {
                                    if (rate == 44100) {
                                        sampleRateSupported = true
                                        break
                                    }
                                    // è®°å½•ç¬¬ä¸€ä¸ªå¯ç”¨çš„é‡‡æ ·ç‡ä½œä¸ºå¤‡é€‰
                                    if (fallbackSampleRate == -1 && (rate == 48000 || rate == 32000 || rate == 16000)) {
                                        fallbackSampleRate = rate
                                    }
                                }
                            } else {
                                // æ²¡æœ‰æ˜ç¡®åˆ—è¡¨æ—¶ï¼Œå°è¯•éªŒè¯44100
                                sampleRateSupported = audioCaps.isSampleRateSupported(44100)
                                if (!sampleRateSupported && audioCaps.isSampleRateSupported(48000)) {
                                    fallbackSampleRate = 48000
                                }
                            }

                            if (!sampleRateSupported && fallbackSampleRate == -1) {
                                Log.d(TAG, "Codec ${codecInfo.name} does not support 44100Hz or any fallback rate, skipping")
                                continue
                            }

                            // éªŒè¯é€šé“æ•°æ”¯æŒ
                            val maxChannels = audioCaps.maxInputChannelCount
                            if (maxChannels < 1) {
                                Log.d(TAG, "Codec ${codecInfo.name} does not support mono audio (maxChannels=$maxChannels), skipping")
                                continue
                            }

                            // æŸ¥æ‰¾æ”¯æŒçš„Profile (ä¼˜å…ˆAAC-LCï¼Œæœ€å…¼å®¹)
                            val profileLevels = caps.profileLevels
                            var supportedProfile = -1

                            if (profileLevels != null && profileLevels.isNotEmpty()) {
                                // ä¼˜å…ˆé€‰æ‹©AAC-LC (Low Complexity) - ç¡¬ä»¶ç¼–è§£ç å™¨é€šå¸¸åªæ”¯æŒè¿™ä¸ª
                                for (pl in profileLevels) {
                                    if (pl.profile == MediaCodecInfo.CodecProfileLevel.AACObjectLC) {
                                        supportedProfile = MediaCodecInfo.CodecProfileLevel.AACObjectLC
                                        break
                                    }
                                }

                                // å¦‚æœæ²¡æœ‰AAC-LCï¼Œå°è¯•å…¶ä»–Profile
                                if (supportedProfile == -1) {
                                    supportedProfile = profileLevels[0].profile
                                    Log.d(TAG, "Codec ${codecInfo.name} does not support AAC-LC, using profile ${supportedProfile}")
                                }
                            } else {
                                // æ²¡æœ‰æ˜ç¡®çš„Profileä¿¡æ¯ï¼Œä½¿ç”¨AAC-LCä½œä¸ºé»˜è®¤å€¼
                                supportedProfile = MediaCodecInfo.CodecProfileLevel.AACObjectLC
                                Log.d(TAG, "Codec ${codecInfo.name} has no profile info, defaulting to AAC-LC")
                            }

                            // ç¼–è§£ç å™¨é€šè¿‡æ‰€æœ‰éªŒè¯ - ç°åœ¨è¿›è¡Œä¼˜å…ˆçº§é€‰æ‹©
                            val isHardwareCodec = codecInfo.name.startsWith("OMX.") ||
                                                 codecInfo.name.startsWith("c2.qcom") ||
                                                 codecInfo.name.startsWith("c2.mtk") ||
                                                 codecInfo.name.startsWith("c2.exynos")

                            val isSoftwareCodec = codecInfo.name.contains("google") ||
                                                 codecInfo.name.contains("sw")

                            Log.d(TAG, "Valid codec found: ${codecInfo.name} (hardware=$isHardwareCodec, profile=$supportedProfile, sampleRate=${if (sampleRateSupported) 44100 else fallbackSampleRate})")

                            // ä¼˜å…ˆé€‰æ‹©ç¡¬ä»¶ç¼–è§£ç å™¨ï¼ˆæ€§èƒ½æ›´å¥½ï¼‰
                            if (isHardwareCodec && selectedCodec == null) {
                                selectedCodec = codecInfo
                                selectedCapabilities = caps
                                selectedProfile = supportedProfile
                                selectedSampleRate = if (sampleRateSupported) 44100 else fallbackSampleRate
                                selectedChannelCount = Math.min(maxChannels, 1)
                                Log.d(TAG, "Selected hardware codec: ${codecInfo.name}")
                                break // æ‰¾åˆ°ç¡¬ä»¶ç¼–è§£ç å™¨åç›´æ¥ä½¿ç”¨
                            }

                            // å¦‚æœæ²¡æ‰¾åˆ°ç¡¬ä»¶ç¼–è§£ç å™¨ï¼Œé™çº§åˆ°è½¯ä»¶ç¼–è§£ç å™¨
                            if (isSoftwareCodec && selectedCodec == null) {
                                selectedCodec = codecInfo
                                selectedCapabilities = caps
                                selectedProfile = supportedProfile
                                selectedSampleRate = if (sampleRateSupported) 44100 else fallbackSampleRate
                                selectedChannelCount = Math.min(maxChannels, 1)
                                Log.d(TAG, "Selected software codec as fallback: ${codecInfo.name}")
                            }

                            // å¦‚æœæ—¢ä¸æ˜¯ç¡¬ä»¶ä¹Ÿä¸æ˜¯è½¯ä»¶ï¼ˆæœªçŸ¥ç±»å‹ï¼‰ï¼Œä½†æ˜¯ç¬¬ä¸€ä¸ªå¯ç”¨çš„ç¼–è§£ç å™¨
                            if (selectedCodec == null) {
                                selectedCodec = codecInfo
                                selectedCapabilities = caps
                                selectedProfile = supportedProfile
                                selectedSampleRate = if (sampleRateSupported) 44100 else fallbackSampleRate
                                selectedChannelCount = Math.min(maxChannels, 1)
                                Log.d(TAG, "Selected unknown-type codec as last resort: ${codecInfo.name}")
                            }

                        } catch (e: Exception) {
                            Log.w(TAG, "Failed to check codec ${codecInfo.name}: ${e.message}")
                            continue
                        }
                    }

                    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å…¼å®¹çš„ç¼–è§£ç å™¨ï¼Œé™çº§ä¸ºçº¯è§†é¢‘å½•åˆ¶
                    if (selectedCodec == null || selectedCapabilities == null) {
                        Log.e(TAG, "No compatible AAC codec found! Falling back to video-only recording")
                        return null
                    }

                    val codec: String = selectedCodec.name
                    val bitrate: Int = Utils.resetAudioBitrateAdapter(selectedCapabilities, -1) * 1000

                    Log.i(TAG, "Final audio config: codec=$codec, profile=$selectedProfile, sampleRate=$selectedSampleRate, channels=$selectedChannelCount, bitrate=$bitrate")

                    return when (source) {
                        ScreenRecordingAudioSource.MIC -> AudioEncodeConfig(
                            codec,
                            ScreenRecorder.AUDIO_AAC,
                            bitrate,
                            selectedSampleRate,
                            selectedChannelCount,
                            selectedProfile,
                            0
                        )
                        ScreenRecordingAudioSource.MIC_AND_INTERNAL -> AudioEncodeConfig(
                            codec,
                            ScreenRecorder.AUDIO_AAC,
                            bitrate,
                            selectedSampleRate,
                            selectedChannelCount,
                            selectedProfile,
                            2
                        )
                        ScreenRecordingAudioSource.INTERNAL -> AudioEncodeConfig(
                            codec,
                            ScreenRecorder.AUDIO_AAC,
                            bitrate,
                            selectedSampleRate,
                            selectedChannelCount,
                            selectedProfile,
                            1
                        )
                        else -> null
                    }
                }
            }
        } catch (e: Exception) {
            Log.w(TAG, "Failed to create audio config, falling back to video-only recording", e)
            return null
        }
    }

    private fun createVideoConfig(): VideoEncodeConfig {
        val codec: String = Utils.mAvcCodecInfos[0].getName()//é€‰æ‹©ç¼–ç å™¨
        val capabilities: CodecCapabilities = Utils.mAvcCodecInfos[0].getCapabilitiesForType(VIDEO_AVC)
        val profile: String = Utils.resetAvcProfileLevelAdapter(capabilities,1)
        val profileLevel: CodecProfileLevel =Utils.toProfileLevel(profile)
        return VideoEncodeConfig(
            getVideoSizeWidth(), getVideoSizeHeight(), 5*getVideoSizeWidth()*getVideoSizeHeight(),
            30, 1, codec, ScreenRecorder.VIDEO_AVC,
            profileLevel
        )
    }

    /**
     * æ³¨æ„:
     * ç³»ç»Ÿåº”ç”¨ android:sharedUserId="android.uid.system" FileProvider åšäº†é™åˆ¶åˆ†äº«ä¸äº†ç»™æ™®é€šåº”ç”¨
     * ä¿å­˜æ–‡ä»¶åˆ°FileCommander
     * å…¶å®å·²ç»ä¿å­˜åˆ° /storage/emulated/0/Vote è¿™ä¸ªç›®å½•ä¸‹ æŠŠUriä¼ åˆ°FileCommander æŒ‡å®šç›®å½•ä¿å­˜èµ·æ¥
     * @param path such as: /storage/emulated/0/Screen Record
     */
    fun saveFileToFileCommander(context: Context, path: String) {
        val packageManager: PackageManager = context.packageManager
        val intent = Intent()
        intent.action = Intent.ACTION_SEND
        intent.type = "*/*"
        val file = File(path)
        intent.type = "*/*"
        val activities = packageManager.queryIntentActivities(intent, 0)
        for (resolveInfo in activities) {
            if ("com.mobisystems.fileman" == resolveInfo.activityInfo.packageName) {
                val targetIntent = Intent()
                targetIntent.action = Intent.ACTION_SEND
                targetIntent.type = "*/*"
                targetIntent.setPackage(resolveInfo.activityInfo.packageName.toLowerCase(Locale.ROOT))
                targetIntent.addFlags(Intent.FLAG_GRANT_WRITE_URI_PERMISSION)
                targetIntent.addFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION)
                val component = ComponentName(
                    resolveInfo.activityInfo.applicationInfo.packageName,
                    resolveInfo.activityInfo.name
                )
                val uri = FileProvider.getUriForFile(
                    context,
                    "com.hht.screenrecoder",
                    file
                )
                Log.d(ScreenRecordService.TAG, "saveFileToFileCommander: $uri")
                val intent1 = Intent(targetIntent)
                intent1.component = component
                intent1.putExtra(Intent.EXTRA_STREAM, uri)
                intent1.type = "*/*"
                intent1.addFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION)
                intent1.addFlags(Intent.FLAG_GRANT_WRITE_URI_PERMISSION)
                intent1.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK)
                context.startActivity(intent1)
            }
        }
    }


    /**
     * æ‰“å¼€åˆ†äº«åº”ç”¨
     * @param path æ–‡ä»¶åœ°å€
     */
    fun startShare(context: Context, path: String) {
        val packageName = "tw.com.hitevision.sharer.MULTIPLE_FILES"
        val intent = Intent()
        intent.component =
            ComponentName("tw.com.hitevision.sharer", "tw.com.hitevision.sharer.MainActivity")
        intent.action = "android.intent.action.MAIN"
        intent.putExtra(packageName, arrayListOf(path))
        intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK)
        context.startActivity(intent)
    }

    /**
     * åŠ è½½éŸ³é¢‘é™éŸ³å¡«å……é…ç½®
     * é€šè¿‡ç³»ç»Ÿå±æ€§åŠ¨æ€é…ç½®ï¼Œä¾¿äºæµ‹è¯•å’Œè°ƒè¯•
     */
    private fun loadAudioSilentFillConfig(): AudioSilentFillConfig {
        val config = AudioSilentFillConfig()

        // ===== è¯»å–å¼€å…³çŠ¶æ€ï¼ˆæœ€é‡è¦çš„é…ç½®ï¼‰ =====
        val enabledStr = getSystemProperty("debug.screenrecord.silent_fill_enabled", "1")
        config.isEnabled = enabledStr == "1" || enabledStr.equals("true", ignoreCase = true)
        config.isEnabled = true //å¼€å¯æ™ºèƒ½é™éŸ³å¡«å……

        // ===== è¯»å–å¢™é’Ÿ PTS æ¨¡å¼ï¼ˆç”»é¢ä¼˜å…ˆï¼‰=====
        val useWallClockStr = getSystemProperty("debug.screenrecord.use_wallclock_pts", "1")
        val useWallClock = useWallClockStr == "1" || useWallClockStr.equals("true", ignoreCase = true)

        // è®¾ç½®å¢™é’Ÿ PTS æ¨¡å¼
        mRecorder?.setUseWallClockPTS(useWallClock)
        Log.i(TAG, "â˜…â˜…â˜… WALL CLOCK PTS MODE â˜…â˜…â˜… enabled=$useWallClock (true=ç”»é¢ä¼˜å…ˆ/å…è®¸éŸ³é¢‘ä¸¢å¤±, false=é‡‡æ ·æ•°è®¡ç®—)")

        // è¯»å–ç³»ç»Ÿå±æ€§é…ç½®æ¨¡å¼ï¼ˆä½¿ç”¨åå°„è®¿é—®éšè—APIï¼‰
        val modeStr = getSystemProperty("debug.screenrecord.silent_mode", "1")

        val mode = when (modeStr.toIntOrNull() ?: 1) {
            1 -> AudioSilentFillConfig.SilentFillMode.LOW_AMPLITUDE_NOISE
            2 -> AudioSilentFillConfig.SilentFillMode.FIXED_LOW_VALUE
            3 -> AudioSilentFillConfig.SilentFillMode.REDUCED_SAMPLE_RATE
            4 -> AudioSilentFillConfig.SilentFillMode.ZERO_WITH_PTS_COMPENSATION
            5 -> AudioSilentFillConfig.SilentFillMode.HYBRID
            else -> AudioSilentFillConfig.SilentFillMode.LOW_AMPLITUDE_NOISE
        }
        config.mode = mode

        // è¯»å–å…¶ä»–å‚æ•°
        config.noiseAmplitude = getSystemProperty("debug.screenrecord.silent_amplitude", "3").toIntOrNull() ?: 3
        config.skipInterval = getSystemProperty("debug.screenrecord.silent_skip_interval", "5").toIntOrNull() ?: 5
        config.initialPeriodMs = getSystemProperty("debug.screenrecord.silent_initial_period", "10000").toLongOrNull() ?: 10000

        Log.i(TAG, "â˜…â˜…â˜… LOADED AUDIO SILENT FILL CONFIG â˜…â˜…â˜… enabled=${config.isEnabled}, mode=$mode, amplitude=${config.noiseAmplitude}, skipInterval=${config.skipInterval}, initialPeriod=${config.initialPeriodMs}ms")
        return config
    }

    /**
     * ä½¿ç”¨åå°„è·å–ç³»ç»Ÿå±æ€§
     */
    private fun getSystemProperty(key: String, defaultValue: String): String {
        return try {
            val clazz = Class.forName("android.os.SystemProperties")
            val method = clazz.getMethod("get", String::class.java, String::class.java)
            method.invoke(null, key, defaultValue) as String
        } catch (e: Exception) {
            Log.w(TAG, "Failed to read system property $key, using default: $defaultValue", e)
            defaultValue
        }
    }

    /**
     * è®¾ç½®éŸ³é¢‘é™éŸ³å¡«å……æ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰
     * @param mode å¡«å……æ¨¡å¼
     * @param amplitude å™ªå£°å¹…åº¦ï¼ˆä»…æ¨¡å¼1ä½¿ç”¨ï¼‰
     */
    fun setAudioSilentFillMode(mode: AudioSilentFillConfig.SilentFillMode, amplitude: Int = 3) {
        val config = AudioSilentFillConfig()
        config.mode = mode
        config.noiseAmplitude = amplitude
        mRecorder?.setAudioSilentFillConfig(config)
        Log.i(TAG, "â˜…â˜…â˜… AUDIO SILENT FILL MODE SET â˜…â˜…â˜… mode=$mode, amplitude=$amplitude")
    }

    companion object {
        private const val VIDEO_SIZE_MAX_WIDTH_1920 = 1920
        private const val VIDEO_SIZE_MAX_HEIGHT_1080 = 1080
        private const val VIDEO_SIZE_MAX_WIDTH_1280 = 1280
        private const val VIDEO_SIZE_MAX_HEIGHT_720 = 720
        private const val VIDEO_SIZE_MAX_WIDTH_3840 = 3840
        private const val VIDEO_SIZE_MAX_HEIGHT_2160 = 2160
        private const val VIDEO_SIZE_MAX_WIDTH_960 = 960
        private const val TAG = "ScreenRecordHelper"
    }

    interface OnVideoRecordListener {
        fun onBeforeRecord()
        fun onStartRecord()
        fun onPauseRecord()
        fun onCancelRecord()
        fun onEndRecord()

        /**
         * å½“æ£€æµ‹åˆ°ç³»ç»Ÿä¸æ”¯æŒå†…ç½®å£°éŸ³å½•åˆ¶æ—¶è°ƒç”¨
         * @param audioType éŸ³é¢‘ç±»å‹ï¼š0=MIC, 1=INTERNAL, 2=MIC_AND_INTERNAL
         */
        fun onInternalAudioNotAvailable(audioType: Int) {
            // é»˜è®¤ç©ºå®ç°
        }
    }

}

